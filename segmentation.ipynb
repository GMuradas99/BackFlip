{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('models/'):\n",
    "  print('Downloading Model')\n",
    "  os.mkdir('models/')\n",
    "  urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth', 'models/defaultModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, length):\n",
    "    \"\"\"\n",
    "    Resize the given image while maintaining its aspect ratio.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image to be resized.\n",
    "    length (int): The desired length (either width or height) of the resized image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The resized image.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the current dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    if height > width:\n",
    "        is_height = True\n",
    "    else:\n",
    "        is_height = False\n",
    "\n",
    "    if is_height:\n",
    "        # Calculate the new width based on the provided height\n",
    "        new_width = int((length / height) * width)\n",
    "        # Resize the image using the new dimensions\n",
    "        resized_image = cv2.resize(image, (new_width, length))\n",
    "    else:\n",
    "        # Calculate the new height based on the provided width\n",
    "        new_height = int((length / width) * height)\n",
    "        # Resize the image using the new dimensions\n",
    "        resized_image = cv2.resize(image, (length, new_height))\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "def pre_segmentate(image_dir: str, size: int, max_num_of_segments: int = 5, output_dir_masks: str = 'segments', output_dir_img: str = None,\n",
    "                   model_checkpoint: str = 'models/defaultModel.pth'):\n",
    "    \"\"\"\n",
    "    Pre-segmentates images in the given directory.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): The directory path containing the images to be pre-segmented.\n",
    "        size (int): The desired size of the pre-segmented images.\n",
    "        max_num_of_segments (int, optional): The maximum number of segments to be generated for each image. Defaults to 5.\n",
    "        output_dir_masks (str, optional): The directory path to save the generated segment masks. Defaults to 'segments'.\n",
    "        output_dir_img (str, optional): The directory path to save the resized images. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    if not os.path.isdir(output_dir_masks):\n",
    "        os.mkdir(output_dir_masks)\n",
    "    if output_dir_img is not None and not os.path.isdir(output_dir_img):\n",
    "        os.mkdir(output_dir_img)\n",
    "    \n",
    "    # Loading sam model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using:',device)\n",
    "    sam = sam_model_registry['default'](checkpoint=model_checkpoint).to(device)\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "    # Iterate over all images in the directory\n",
    "    for file in tqdm(os.listdir(image_dir)):\n",
    "        image_name = file[:file.rfind('.')]\n",
    "\n",
    "        # Check if image was already segmented\n",
    "        if os.path.isdir(os.path.join(output_dir_masks, image_name)):\n",
    "            continue         \n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(os.path.join(image_dir, file))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = resize_image(image, size)\n",
    "\n",
    "        # Save resized image\n",
    "        if output_dir_img is not None:\n",
    "            cv2.imwrite(os.path.join(output_dir_img, image_name + '.png'), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Generate masks\n",
    "        masks = mask_generator.generate(image)\n",
    "\n",
    "        # Segment selection #################################################################\n",
    "        masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "        selected = []\n",
    "        for mask in masks:\n",
    "            # Check if the bbox is too big\n",
    "            bboxArea = (mask['bbox'][2] - mask['bbox'][0]) * (mask['bbox'][3] - mask['bbox'][1])\n",
    "            imgArea = image.shape[0] * image.shape[1]\n",
    "            if bboxArea/imgArea <= 0.9:\n",
    "                selected.append(mask)\n",
    "\n",
    "            if len(selected) == max_num_of_segments:\n",
    "                break\n",
    "\n",
    "        #Save masks\n",
    "        os.mkdir(os.path.join(output_dir_masks, image_name))\n",
    "        for i,mask in enumerate(selected):\n",
    "            toSave = mask['segmentation'].astype(np.uint8) * 255\n",
    "            cv2.imwrite(os.path.join(output_dir_masks, image_name, f'{i}.png'), toSave)\n",
    "\n",
    "            \n",
    "pre_segmentate('datasets/GonAesthetics', 224, output_dir_img='resized_images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backflip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
